{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "import keras.losses\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    # Import csv file\n",
    "    raw = pd.read_csv(file)\n",
    "    train = raw[raw['Usage'] == 'Training']\n",
    "    train_pixels = train['pixels']\n",
    "    train_y = train['emotion'].values\n",
    "    \n",
    "    test = raw[raw['Usage'] == 'PublicTest']\n",
    "    test_pixels = test['pixels']\n",
    "    test_y = test['emotion'].values\n",
    "    \n",
    "    # Convert raw training pixel data into numpy array\n",
    "    train_x = []\n",
    "    for image in train_pixels:\n",
    "        temp = [int(n) for n in image.split()]\n",
    "        train_x.append(temp)\n",
    "    train_x = np.asarray(train_x)\n",
    "    train_x = np.resize(train_x, (len(train_pixels),1, 48, 48))\n",
    "    \n",
    "    # Convert raw testing pixel data into numpy arrays\n",
    "    test_x = []\n",
    "    for image in test_pixels:\n",
    "        temp = [int(n) for n in image.split()]\n",
    "        test_x.append(temp)\n",
    "    test_x = np.asarray(test_x)\n",
    "    test_x = np.resize(test_x, (len(test_pixels), 1, 48, 48))\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = parse_data('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = class_weight.compute_class_weight('balanced', np.unique(train_y), train_y)\n",
    "train_y = np_utils.to_categorical(train_y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    data_format='channels_first')\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_shape = (1, 48, 48)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_first', activation='relu', input_shape=in_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GaussianNoise(0.3))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(5,5), strides=(1,1), padding='same', data_format='channels_first', activation='relu', input_shape=in_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_first', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(GaussianNoise(0.3))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_first', activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights\n",
    "# Uncomment below to restore weights if kernel was interrupted during training \n",
    "#model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28709/28709 [==============================] - 83s 3ms/step - loss: 0.4584 - acc: 0.8410\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.84103, saving model to weights-best.hdf5\n",
      "Epoch 2/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.2594 - acc: 0.9106\n",
      "\n",
      "Epoch 00002: acc improved from 0.84103 to 0.91055, saving model to weights-best.hdf5\n",
      "Epoch 3/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.2194 - acc: 0.9265\n",
      "\n",
      "Epoch 00003: acc improved from 0.91055 to 0.92647, saving model to weights-best.hdf5\n",
      "Epoch 4/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.2126 - acc: 0.9280\n",
      "\n",
      "Epoch 00004: acc improved from 0.92647 to 0.92797, saving model to weights-best.hdf5\n",
      "Epoch 5/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.2189 - acc: 0.9263\n",
      "\n",
      "Epoch 00005: acc did not improve\n",
      "Epoch 6/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.2087 - acc: 0.9301\n",
      "\n",
      "Epoch 00006: acc improved from 0.92797 to 0.93009, saving model to weights-best.hdf5\n",
      "Epoch 7/10\n",
      "28709/28709 [==============================] - 79s 3ms/step - loss: 0.1888 - acc: 0.9374\n",
      "\n",
      "Epoch 00007: acc improved from 0.93009 to 0.93737, saving model to weights-best.hdf5\n",
      "Epoch 8/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.1992 - acc: 0.9318\n",
      "\n",
      "Epoch 00008: acc did not improve\n",
      "Epoch 9/10\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.1867 - acc: 0.9381\n",
      "\n",
      "Epoch 00009: acc improved from 0.93737 to 0.93814, saving model to weights-best.hdf5\n",
      "Epoch 10/10\n",
      "28709/28709 [==============================] - 79s 3ms/step - loss: 0.1925 - acc: 0.9371\n",
      "\n",
      "Epoch 00010: acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74168392e8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(train_x, train_y, batch_size=32), \n",
    "                    steps_per_epoch=len(train_x) / 32, epochs=30, class_weight=weights, callbacks=[checkpoint])\n",
    "# Normal model fit\n",
    "model.fit(train_x, train_y, epochs=50, batch_size=30, verbose = 1, class_weight=weights, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = []\n",
    "for value in predictions:\n",
    "    y_hat.append(np.argmax(value))\n",
    "    \n",
    "y_hat = np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
